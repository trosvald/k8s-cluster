---
version: "3"

x-task-vars: &task-vars
  node: "{{.node}}"
  cephDisk: "{{.cephDisk}}"
  ts: "{{.ts}}"
  jobName: "{{.jobName}}"

vars:
  sharedScriptsDir: '{{.ROOT_DIR}}/.taskfiles/shared'
  rookTemplatesDir: '{{.ROOT_DIR}}/.taskfiles/rook/templates'
  ts: '{{now | date "150405"}}'

tasks:
  toolbox:
    desc: Exec into the rook-ceph toolbox
    interactive: true
    cmds:
      - kubectl -n rook-ceph exec -it $(kubectl -n rook-ceph get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}') -- bash

  password:
    desc: Retrieve the rook-ceph password
    cmds:
      - kubectl -n rook-ceph get secret rook-ceph-dashboard-password -o jsonpath="{['data']['password']}" | base64 --decode

  wipe-node-w0:
    desc: Trigger a wipe of Rook-Ceph data on node "w0"
    cmds:
      - task: wipe-disk
        vars:
          node: '{{.node}}'
          cephDisk: /dev/nvme0n1
      - task: wipe-disk
        vars:
          node: '{{.node}}'
          cephDisk: /dev/nvme0n1
      - task: wipe-data
        vars:
          node: '{{.node}}'
    vars:
      node: k8s-w0

  wipe-node-w1:
    desc: Trigger a wipe of Rook-Ceph data on node "w1"
    cmds:
      - task: wipe-disk
        vars:
          node: '{{.node}}'
          cephDisk: /dev/nvme0n1
      - task: wipe-disk
        vars:
          node: '{{.node}}'
          cephDisk: /dev/nvme0n1
      - task: wipe-data
        vars:
          node: '{{.node}}'
    vars:
      node: k8s-w1

  wipe-node-w2:
    desc: Trigger a wipe of Rook-Ceph data on node "w2"
    cmds:
      - task: wipe-disk
        vars:
          node: '{{.node}}'
          cephDisk: /dev/nvme0n1
      - task: wipe-disk
        vars:
          node: '{{.node}}'
          cephDisk: /dev/nvme0n1
      - task: wipe-data
        vars:
          node: '{{.node}}'
    vars:
      node: k8s-w2

  wipe-node-w3:
    desc: Trigger a wipe of Rook-Ceph data on node "w3"
    cmds:
      - task: wipe-disk
        vars:
          node: '{{.node}}'
          cephDisk: /dev/nvme0n1
      - task: wipe-disk
        vars:
          node: '{{.node}}'
          cephDisk: /dev/nvme0n1
      - task: wipe-data
        vars:
          node: '{{.node}}'
    vars:
      node: k8s-w3

  wipe-disk:
    desc: Wipe all remnants of rook-ceph from a given disk (ex. task rook:wipe-disk node=delta ceph_disk="/dev/nvme0n1")
    silent: true
    internal: true
    cmds:
      - envsubst < <(cat {{.rookTemplatesDir}}/WipeDiskJob.tmpl.yaml) | kubectl apply -f -
      - bash {{.sharedScriptsDir}}/wait.sh "{{.jobName}}" default
      - kubectl -n default wait job/{{.jobName}} --for condition=complete --timeout=1m
      - kubectl -n default logs job/{{.jobName}}
      - kubectl -n default delete job {{.jobName}}
    vars:
      node: '{{ or .node (fail "`node` is required") }}'
      cephDisk: '{{ or .cephDisk (fail "`cephDisk` is required") }}'
      jobName: 'wipe-disk-{{- .node -}}-{{- .ts -}}'
    env: *task-vars
    preconditions:
      - sh: test -f {{.sharedScriptsDir}}/wait.sh
      - sh: test -f {{.rookTemplatesDir}}/WipeDiskJob.tmpl.yaml

  wipe-data:
    desc: Wipe all remnants of rook-ceph from a given disk (ex. task rook:wipe-data node=delta)
    silent: true
    internal: true
    cmds:
      - envsubst < <(cat {{.rookTemplatesDir}}/WipeRookDataJob.tmpl.yaml) | kubectl apply -f -
      - bash {{.sharedScriptsDir}}/wait.sh "{{.jobName}}" default
      - kubectl -n default wait job/{{.jobName}} --for condition=complete --timeout=1m
      - kubectl -n default logs job/{{.jobName}}
      - kubectl -n default delete job {{.jobName}}
    vars:
      node: '{{ or .node (fail "`node` is required") }}'
      jobName: 'wipe-rook-data-{{- .node -}}-{{- .ts -}}'
    env: *task-vars
    preconditions:
      - sh: test -f {{.sharedScriptsDir}}/wait.sh
      - sh: test -f {{.rookTemplatesDir}}/WipeRookDataJob.tmpl.yaml
